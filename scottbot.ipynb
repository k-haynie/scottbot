{"cells":[{"cell_type":"markdown","metadata":{"id":"VTze-VbeU1c0"},"source":["# Fine-tune a DialoGPT model\n","\n","Adapted from the notebook in [this Medium post](https://towardsdatascience.com/make-your-own-rick-sanchez-bot-with-transformers-and-dialogpt-fine-tuning-f85e6d1f4e30?gi=e4a72d1510f0)."]},{"cell_type":"markdown","metadata":{"id":"Y17kuzFNUSrZ"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15762,"status":"ok","timestamp":1672271132321,"user":{"displayName":"Kaelyn Haynie","userId":"01388062276589306886"},"user_tz":300},"id":"GBfltjGHT6KG","outputId":"4439ad5e-0f7d-47b1-a564-3369998c5ee1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","# Taken from the tutorial: https://towardsdatascience.com/make-your-own-rick-sanchez-bot-with-transformers-and-dialogpt-fine-tuning-f85e6d1f4e30"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10722,"status":"ok","timestamp":1672271143039,"user":{"displayName":"Kaelyn Haynie","userId":"01388062276589306886"},"user_tz":300},"id":"T8fgmjaqUErq","outputId":"2e98e7f9-8a7b-4a01-d216-7c70414f99c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 5.8 MB 26.0 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 68.6 MB/s \n","\u001b[K     |████████████████████████████████| 7.6 MB 60.4 MB/s \n","\u001b[?25h"]}],"source":["!pip -q install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtCreyG8UG1s"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnv5kT-mLsB-"},"outputs":[],"source":["# all the imports\n","\n","import glob\n","import logging\n","import os\n","import pickle\n","import random\n","import re\n","import shutil\n","from typing import Dict, List, Tuple\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm.notebook import tqdm, trange\n","\n","from pathlib import Path\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","\n","try:\n","    from torch.utils.tensorboard import SummaryWriter\n","except ImportError:\n","    from tensorboardX import SummaryWriter"]},{"cell_type":"markdown","metadata":{"id":"BmrbGB8aUmBm"},"source":["## Get Data from Kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXdJTSVwWGHj"},"outputs":[],"source":["data = pd.read_csv('parsed_office.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1672271153668,"user":{"displayName":"Kaelyn Haynie","userId":"01388062276589306886"},"user_tz":300},"id":"h6kGx-9eG7qA","outputId":"dc4b3268-9289-4c12-d049-98a2bb6a0a78"},"outputs":[{"data":{"text/plain":["11806"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["data.sample(6)\n","sum(data[\"Character\"] == \"Michael\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PG8v6--qWUwj"},"outputs":[],"source":["CHARACTER_NAME = 'Michael'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZUcEMd2WLDT"},"outputs":[],"source":["contexted = []\n","\n","# context window of size 7\n","n = 7\n","\n","for i in data[data.Character == CHARACTER_NAME].index:\n","  if i < n:\n","    continue\n","  row = []\n","  prev = i - 1 - n # we additionally substract 1, so row will contain current responce and 7 previous responces  \n","  for j in range(i, prev, -1):\n","    row.append(data.Line[j])\n","  contexted.append(row)\n","\n","columns = ['response', 'context'] \n","columns = columns + ['context/' + str(i) for i in range(n - 1)]\n","\n","df = pd.DataFrame.from_records(contexted, columns=columns).dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1672271154602,"user":{"displayName":"Kaelyn Haynie","userId":"01388062276589306886"},"user_tz":300},"id":"4T5OlNZHUxij","outputId":"1a803b4b-6ae2-4596-a501-8c249b652fce"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-8d34a09e-0484-4345-be16-65a721121c98\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>response</th>\n","      <th>context</th>\n","      <th>context/0</th>\n","      <th>context/1</th>\n","      <th>context/2</th>\n","      <th>context/3</th>\n","      <th>context/4</th>\n","      <th>context/5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>282</th>\n","      <td>Hey, Oscar! Come on in. What’s up?</td>\n","      <td>Meredith, Meredith… Meri… Mary had a little la...</td>\n","      <td>Because we’re strong, Dwight. Because we’re st...</td>\n","      <td>God… Damn it! Why us?</td>\n","      <td>OK, listen, we need to assume that everyone in...</td>\n","      <td>Damn it. God!</td>\n","      <td>Their bread is very good.</td>\n","      <td>Their bread’s really good.</td>\n","    </tr>\n","    <tr>\n","      <th>6990</th>\n","      <td>Is there no way we can get rid of him?</td>\n","      <td>No.</td>\n","      <td>David, wait.</td>\n","      <td>Okay, I have to go.</td>\n","      <td>That’s true.  People say it’s icky.</td>\n","      <td>Also, it’s icky back there.</td>\n","      <td>I did not want to go back to the annex because...</td>\n","      <td>Now what I’m curious about is how you were abl...</td>\n","    </tr>\n","    <tr>\n","      <th>3724</th>\n","      <td>That is my Christmas card. It’s a picture of y...</td>\n","      <td>What is this?</td>\n","      <td>Not as much as I need a moment alone with you....</td>\n","      <td>I really need a moment alone with you.</td>\n","      <td>Thank you.</td>\n","      <td>Oh, ouch. Michael, I don’t think there is anyt...</td>\n","      <td>If I may say. She’s even prettier that you des...</td>\n","      <td>Yes.</td>\n","    </tr>\n","    <tr>\n","      <th>6318</th>\n","      <td>It was early morning yesterday… I was up befor...</td>\n","      <td>Yeah.</td>\n","      <td>I love to sing them, but I am not going to be ...</td>\n","      <td>I like that one.</td>\n","      <td>It’s not my favorite…</td>\n","      <td>I like that one.</td>\n","      <td>Not my favorite, but…</td>\n","      <td>Or, “Total Eclipse of the Fart.”</td>\n","    </tr>\n","    <tr>\n","      <th>1185</th>\n","      <td>Of course. You’re always working hard.</td>\n","      <td>Mmm-hmm.</td>\n","      <td>Hey, you. Big Jim. And Phyllis. Working hard, ...</td>\n","      <td>You’re a lion.  Wow, I want to hear your, your...</td>\n","      <td>I’m a lion.</td>\n","      <td>A fairy princess. You’re very… .</td>\n","      <td>A fairy princess.</td>\n","      <td>You look great! And you’re a princess?</td>\n","    </tr>\n","    <tr>\n","      <th>5126</th>\n","      <td>So older people have just as many rights as yo...</td>\n","      <td>Ageism? Companies they can’t discriminate agai...</td>\n","      <td>What is that… word?</td>\n","      <td>I hope he’s gets hit with an ageism suit.</td>\n","      <td>Well…</td>\n","      <td>He’s such a snake.</td>\n","      <td>Oh, I dunno, they’re launching a big new busin...</td>\n","      <td>So, what’s Ryan doing here?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d34a09e-0484-4345-be16-65a721121c98')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8d34a09e-0484-4345-be16-65a721121c98 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8d34a09e-0484-4345-be16-65a721121c98');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               response  \\\n","282                  Hey, Oscar! Come on in. What’s up?   \n","6990             Is there no way we can get rid of him?   \n","3724  That is my Christmas card. It’s a picture of y...   \n","6318  It was early morning yesterday… I was up befor...   \n","1185             Of course. You’re always working hard.   \n","5126  So older people have just as many rights as yo...   \n","\n","                                                context  \\\n","282   Meredith, Meredith… Meri… Mary had a little la...   \n","6990                                                No.   \n","3724                                      What is this?   \n","6318                                              Yeah.   \n","1185                                           Mmm-hmm.   \n","5126  Ageism? Companies they can’t discriminate agai...   \n","\n","                                              context/0  \\\n","282   Because we’re strong, Dwight. Because we’re st...   \n","6990                                       David, wait.   \n","3724  Not as much as I need a moment alone with you....   \n","6318  I love to sing them, but I am not going to be ...   \n","1185  Hey, you. Big Jim. And Phyllis. Working hard, ...   \n","5126                                What is that… word?   \n","\n","                                              context/1  \\\n","282                               God… Damn it! Why us?   \n","6990                                Okay, I have to go.   \n","3724             I really need a moment alone with you.   \n","6318                                   I like that one.   \n","1185  You’re a lion.  Wow, I want to hear your, your...   \n","5126          I hope he’s gets hit with an ageism suit.   \n","\n","                                              context/2  \\\n","282   OK, listen, we need to assume that everyone in...   \n","6990                That’s true.  People say it’s icky.   \n","3724                                         Thank you.   \n","6318                              It’s not my favorite…   \n","1185                                        I’m a lion.   \n","5126                                              Well…   \n","\n","                                              context/3  \\\n","282                                       Damn it. God!   \n","6990                        Also, it’s icky back there.   \n","3724  Oh, ouch. Michael, I don’t think there is anyt...   \n","6318                                   I like that one.   \n","1185                   A fairy princess. You’re very… .   \n","5126                                 He’s such a snake.   \n","\n","                                              context/4  \\\n","282                           Their bread is very good.   \n","6990  I did not want to go back to the annex because...   \n","3724  If I may say. She’s even prettier that you des...   \n","6318                              Not my favorite, but…   \n","1185                                  A fairy princess.   \n","5126  Oh, I dunno, they’re launching a big new busin...   \n","\n","                                              context/5  \n","282                          Their bread’s really good.  \n","6990  Now what I’m curious about is how you were abl...  \n","3724                                               Yes.  \n","6318                   Or, “Total Eclipse of the Fart.”  \n","1185             You look great! And you’re a princess?  \n","5126                        So, what’s Ryan doing here?  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.sample(6)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1672271154770,"user":{"displayName":"Kaelyn Haynie","userId":"01388062276589306886"},"user_tz":300},"id":"NGy0MxMQVIAP","outputId":"f83d9485-c0a7-475e-9160-3234a1972afe"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-78ac725b-4dd8-47f1-9f42-337f2725ba52\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>response</th>\n","      <th>context</th>\n","      <th>context/0</th>\n","      <th>context/1</th>\n","      <th>context/2</th>\n","      <th>context/3</th>\n","      <th>context/4</th>\n","      <th>context/5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10691</th>\n","      <td>It was a good idea, though.</td>\n","      <td>No. Shh. Michael, listen. This cannot stand. W...</td>\n","      <td>What is taking someone from behind?</td>\n","      <td>He went over your head to go behind your back.</td>\n","      <td>No, he didn’t go behind my back. He went over ...</td>\n","      <td>He went to Gabe behind your back.</td>\n","      <td>I’m a little peeved at Darryl right now.</td>\n","      <td>Uh uh. Corporate stole nothing, okay? Darryl t...</td>\n","    </tr>\n","    <tr>\n","      <th>2635</th>\n","      <td>Uhhh… blow out the candle. Okay. Mmmm…</td>\n","      <td>Here we go. Make a wish.</td>\n","      <td>Are you done? …Good. Okay.</td>\n","      <td>No, um, no not yet. I will. Bye.  It was just ...</td>\n","      <td>Kevin? Respect the birthday please.</td>\n","      <td>Hello? Hey.</td>\n","      <td>Happy birthday dear Michael,  Happy birthday… ...</td>\n","      <td>…Okay.</td>\n","    </tr>\n","    <tr>\n","      <th>11262</th>\n","      <td>Don’t go. I don’t want you to go. Oh don’t go....</td>\n","      <td>Okay, one more quick one.</td>\n","      <td>Okay, bye. Bye. All right, bye. Bye… bye.</td>\n","      <td>Bye.</td>\n","      <td>Miss you. Okay. I’ll be in my office if you ne...</td>\n","      <td>Okay, bye. Okay, bye.  I’ll miss you.</td>\n","      <td>Blue Wasabi is so good, but get the cheeseburg...</td>\n","      <td>Nice. Do the damn thing. – Pow!</td>\n","    </tr>\n","    <tr>\n","      <th>7366</th>\n","      <td>Stay  calm!</td>\n","      <td>What’s the procedure, everyone? What’s the pro...</td>\n","      <td>Oh my God! Okay, it happening.  Everybody stay...</td>\n","      <td>No, we don’t know that.  The smoke could be co...</td>\n","      <td>It’s out in the hall.</td>\n","      <td>Oh, how did that happen?</td>\n","      <td>The phones are dead.</td>\n","      <td>Oh, fire!  Oh my goodness!  What’s the procedu...</td>\n","    </tr>\n","    <tr>\n","      <th>8825</th>\n","      <td>Take that thing off the table! Please!</td>\n","      <td>Forget it! Forget it!</td>\n","      <td>You’re wearing loafers!</td>\n","      <td>Should I change?</td>\n","      <td>Let’s go, come on.  God!</td>\n","      <td>To change tires, no. But it’s metal, I can hit...</td>\n","      <td>Do you know how to use it?</td>\n","      <td>Well if I’m gonna back you up, I need a weapon...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78ac725b-4dd8-47f1-9f42-337f2725ba52')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-78ac725b-4dd8-47f1-9f42-337f2725ba52 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-78ac725b-4dd8-47f1-9f42-337f2725ba52');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                response  \\\n","10691                        It was a good idea, though.   \n","2635              Uhhh… blow out the candle. Okay. Mmmm…   \n","11262  Don’t go. I don’t want you to go. Oh don’t go....   \n","7366                                         Stay  calm!   \n","8825              Take that thing off the table! Please!   \n","\n","                                                 context  \\\n","10691  No. Shh. Michael, listen. This cannot stand. W...   \n","2635                            Here we go. Make a wish.   \n","11262                          Okay, one more quick one.   \n","7366   What’s the procedure, everyone? What’s the pro...   \n","8825                               Forget it! Forget it!   \n","\n","                                               context/0  \\\n","10691                What is taking someone from behind?   \n","2635                          Are you done? …Good. Okay.   \n","11262          Okay, bye. Bye. All right, bye. Bye… bye.   \n","7366   Oh my God! Okay, it happening.  Everybody stay...   \n","8825                             You’re wearing loafers!   \n","\n","                                               context/1  \\\n","10691     He went over your head to go behind your back.   \n","2635   No, um, no not yet. I will. Bye.  It was just ...   \n","11262                                               Bye.   \n","7366   No, we don’t know that.  The smoke could be co...   \n","8825                                    Should I change?   \n","\n","                                               context/2  \\\n","10691  No, he didn’t go behind my back. He went over ...   \n","2635                 Kevin? Respect the birthday please.   \n","11262  Miss you. Okay. I’ll be in my office if you ne...   \n","7366                               It’s out in the hall.   \n","8825                            Let’s go, come on.  God!   \n","\n","                                               context/3  \\\n","10691                  He went to Gabe behind your back.   \n","2635                                         Hello? Hey.   \n","11262              Okay, bye. Okay, bye.  I’ll miss you.   \n","7366                            Oh, how did that happen?   \n","8825   To change tires, no. But it’s metal, I can hit...   \n","\n","                                               context/4  \\\n","10691           I’m a little peeved at Darryl right now.   \n","2635   Happy birthday dear Michael,  Happy birthday… ...   \n","11262  Blue Wasabi is so good, but get the cheeseburg...   \n","7366                                The phones are dead.   \n","8825                          Do you know how to use it?   \n","\n","                                               context/5  \n","10691  Uh uh. Corporate stole nothing, okay? Darryl t...  \n","2635                                              …Okay.  \n","11262                    Nice. Do the damn thing. – Pow!  \n","7366   Oh, fire!  Oh my goodness!  What’s the procedu...  \n","8825   Well if I’m gonna back you up, I need a weapon...  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["trn_df, val_df = train_test_split(df, test_size=0.1)\n","trn_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEeJQlAKWtiJ"},"outputs":[],"source":["# create dataset suitable for our model\n","def construct_conv(row, tokenizer, eos = True):\n","    flatten = lambda l: [item for sublist in l for item in sublist]\n","    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n","    conv = flatten(conv)\n","    return conv\n","\n","class ConversationDataset(Dataset):\n","    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n","\n","        block_size = block_size - (tokenizer.model_max_length - tokenizer.max_len_single_sentence)\n","\n","        directory = args.cache_dir\n","        cached_features_file = os.path.join(\n","            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n","        )\n","\n","        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n","            logger.info(\"Loading features from cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"rb\") as handle:\n","                self.examples = pickle.load(handle)\n","        else:\n","            logger.info(\"Creating features from dataset file at %s\", directory)\n","\n","            self.examples = []\n","            for _, row in df.iterrows():\n","                conv = construct_conv(row, tokenizer)\n","                self.examples.append(conv)\n","\n","            logger.info(\"Saving features into cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"wb\") as handle:\n","                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, item):\n","        return torch.tensor(self.examples[item], dtype=torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3iHwoKlWyrs"},"outputs":[],"source":["# Cacheing and storing of data/checkpoints\n","\n","def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n","    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n","\n","\n","def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    if args.n_gpu > 0:\n","        torch.cuda.manual_seed_all(args.seed)\n","\n","\n","def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n","    ordering_and_checkpoint_path = []\n","\n","    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n","\n","    for path in glob_checkpoints:\n","        if use_mtime:\n","            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n","        else:\n","            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n","            if regex_match and regex_match.groups():\n","                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n","\n","    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n","    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n","    return checkpoints_sorted\n","\n","\n","def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n","    if not args.save_total_limit:\n","        return\n","    if args.save_total_limit <= 0:\n","        return\n","\n","    # Check if we should delete older checkpoint(s)\n","    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n","    if len(checkpoints_sorted) <= args.save_total_limit:\n","        return\n","\n","    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n","    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n","    for checkpoint in checkpoints_to_be_deleted:\n","        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n","        shutil.rmtree(checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"EEDdTJTqUwZJ"},"source":["## Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200,"referenced_widgets":["cde87ff273a1498e950cd4b3a61f76cc","5bf590a2c9244052866b574df710d953","57e2fa39f626464b9be881a2c216e5ec","bb3051de7d234ec085ca9de6b92233c0","d282dc72caad44c6afe68e5aa74ecff9","69d4288ed8e042d6a6fe0f84d26962df","9627f4b745614fa69f5af654c6341a15","13834fe4c44d4e9699a4ec6cef8a3bf1","ede9f0142c724774a01d404f5f357d5b","812e5a3792c541e5b8e3e1eca87fd6e7","2c1a478f25044ce58205cbea01a56f75","f266e1f7c0154223b904d8e2852fd516","e0b619a72e58439eb0e85126df06fca5","3cf9cc28a46a484dad37666d8bd999e1","c676803768654d97905d69639a26dde9","c1a1aac141264f23953eff258fe973a4","c96dd189c1a241ee87dacfcea226d899","0c5df579ff9e45eb8cc7a5ba9bfb782a","1910a2d3dbe8486b92036a86a520dff9","86bcecbbe3674795868e2b96e0d06cdf","188861195b2944bb923d96d49ef92893","6b669292096d43f7a7f49c48961123fc","69d95883e5e7463ea1e5c4398223d556","4f5fc5b1d77342cf8eae01d4098ceda1","1fa7ac1526e748e49657a00d09b7be84","ed2c171253a241cd99059585d360886a","0fb3ead434684e11a03ec8561d7829d9","1415c4ad9cbf444081505bdb1e616329","b9b2bbf4702549c5beccc5e4595339ac","9267d8c8ab97417c87657c21fbffac8c","9f20154f1f464c42b6d6155b2d75ba7d","400f1dae2a804290a25b6d201de170e3","54a9a19e3ac54075aacefd37773b5dfa","e60c02ffbb9b4d7cb883cb8aacd0db1a","59388534c15a4137953e6dd57c25e07a","06bb6abc2dcc4c169416f61ee36d8cef","389d237c82074e26a08a23591abc8d60","853149eb994c4635a7179fed0653da25","6d6d4f2facfd4eeb88be434a1518b5cc","da6526b5b0104a4ea191ea979fcab535","386fbd302fbb4c609d1d8ad7633690d2","c76d7d5ebfa744abbf0d6ed503deb919","a8c412b1329f4114b224acf346c64e0b","234d1e2c2aab406c9e82c6f21bcc518e"]},"executionInfo":{"elapsed":29448,"status":"ok","timestamp":1672271184212,"user":{"displayName":"Kaelyn Haynie","userId":"01388062276589306886"},"user_tz":300},"id":"r2cE0fY5UHpz","outputId":"a2bc2048-5867-4500-e89b-33b66050d5a4"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cde87ff273a1498e950cd4b3a61f76cc","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f266e1f7c0154223b904d8e2852fd516","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69d95883e5e7463ea1e5c4398223d556","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e60c02ffbb9b4d7cb883cb8aacd0db1a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/models/auto/modeling_auto.py:1177: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoModelWithLMHead, AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n","model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-medium\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ra2vsRp-UMXo"},"outputs":[],"source":["\"\"\"\n","Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n","GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n","using a masked language modeling (MLM) loss.\n","\"\"\"\n","\n","# Configs\n","logger = logging.getLogger(__name__)\n","\n","MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n","MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2OnASqJjUNJa"},"outputs":[],"source":["# Args to allow for easy convertion of python script to notebook\n","class Args():\n","    def __init__(self):\n","        self.output_dir = 'output-medium'\n","        self.model_type = 'gpt2'\n","        self.model_name_or_path = 'microsoft/DialoGPT-medium'\n","        self.config_name = 'microsoft/DialoGPT-medium'\n","        self.tokenizer_name = 'microsoft/DialoGPT-medium'\n","        self.cache_dir = 'cached'\n","        self.block_size = 512\n","        self.do_train = True\n","        self.do_eval = True\n","        self.evaluate_during_training = False\n","        self.per_gpu_train_batch_size = 4\n","        self.per_gpu_eval_batch_size = 4\n","        self.gradient_accumulation_steps = 1\n","        self.learning_rate = 5e-5\n","        self.weight_decay = 0.0\n","        self.adam_epsilon = 1e-8\n","        self.max_grad_norm = 1.0\n","        self.num_train_epochs = 4\n","        self.max_steps = -1\n","        self.warmup_steps = 0\n","        self.logging_steps = 1000\n","        self.save_steps = 3500\n","        self.save_total_limit = None\n","        self.eval_all_checkpoints = False\n","        self.no_cuda = False\n","        self.overwrite_output_dir = True\n","        self.overwrite_cache = True\n","        self.should_continue = False\n","        self.seed = 42\n","        self.local_rank = -1\n","        self.fp16 = False\n","        self.fp16_opt_level = 'O1'\n","\n","args = Args()"]},{"cell_type":"markdown","metadata":{"id":"9Q1dTFXxW9NE"},"source":["## Train and Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PaarIDZrW81h"},"outputs":[],"source":["def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n","    \"\"\" Train the model \"\"\"\n","    if args.local_rank in [-1, 0]:\n","        tb_writer = SummaryWriter()\n","\n","    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n","    train_dataloader = DataLoader(\n","        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    if args.max_steps > 0:\n","        t_total = args.max_steps\n","        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n","    else:\n","        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","\n","    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n","    model.resize_token_embeddings(len(tokenizer))\n","    # add_special_tokens_(model, tokenizer)\n","\n","\n","    # Prepare optimizer and schedule (linear warmup and decay)\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": args.weight_decay,\n","        },\n","        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n","    )\n","\n","    # Check if saved optimizer or scheduler states exist\n","    if (\n","        args.model_name_or_path\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n","    ):\n","        # Load in optimizer and scheduler states\n","        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n","        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n","\n","    if args.fp16:\n","        try:\n","            from apex import amp\n","        except ImportError:\n","            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n","        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n","\n","    # multi-gpu training (should be after apex fp16 initialization)\n","    if args.n_gpu > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Distributed training (should be after apex fp16 initialization)\n","    if args.local_rank != -1:\n","        model = torch.nn.parallel.DistributedDataParallel(\n","            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n","        )\n","\n","    # Train!\n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(train_dataset))\n","    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n","    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n","    logger.info(\n","        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n","        args.train_batch_size\n","        * args.gradient_accumulation_steps\n","        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n","    )\n","    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","    global_step = 0\n","    epochs_trained = 0\n","    steps_trained_in_current_epoch = 0\n","    # Check if continuing training from a checkpoint\n","    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n","        try:\n","            # set global_step to gobal_step of last saved checkpoint from model path\n","            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n","            global_step = int(checkpoint_suffix)\n","            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n","            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n","\n","            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n","            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n","            logger.info(\"  Continuing training from global step %d\", global_step)\n","            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n","        except ValueError:\n","            logger.info(\"  Starting fine-tuning.\")\n","\n","    tr_loss, logging_loss = 0.0, 0.0\n","\n","    model.zero_grad()\n","    train_iterator = trange(\n","        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n","    )\n","    set_seed(args)  # Added here for reproducibility\n","    for _ in train_iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n","        for step, batch in enumerate(epoch_iterator):\n","\n","            # Skip past any already trained steps if resuming training\n","            if steps_trained_in_current_epoch > 0:\n","                steps_trained_in_current_epoch -= 1\n","                continue\n","\n","            inputs, labels = (batch, batch)\n","            if inputs.shape[1] > 1024: continue\n","            inputs = inputs.to(args.device)\n","            labels = labels.to(args.device)\n","            model.train()\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n","\n","            if args.n_gpu > 1:\n","                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n","            if args.gradient_accumulation_steps > 1:\n","                loss = loss / args.gradient_accumulation_steps\n","\n","            if args.fp16:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            tr_loss += loss.item()\n","            if (step + 1) % args.gradient_accumulation_steps == 0:\n","                if args.fp16:\n","                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n","                else:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n","                    # Log metrics\n","                    if (\n","                        args.local_rank == -1 and args.evaluate_during_training\n","                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n","                        results = evaluate(args, model, tokenizer)\n","                        for key, value in results.items():\n","                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n","                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n","                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n","                    logging_loss = tr_loss\n","\n","                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n","                    checkpoint_prefix = \"checkpoint\"\n","                    # Save model checkpoint\n","                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n","                    os.makedirs(output_dir, exist_ok=True)\n","                    model_to_save = (\n","                        model.module if hasattr(model, \"module\") else model\n","                    )  # Take care of distributed/parallel training\n","                    model_to_save.save_pretrained(output_dir)\n","                    tokenizer.save_pretrained(output_dir)\n","\n","                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n","                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n","\n","                    _rotate_checkpoints(args, checkpoint_prefix)\n","\n","                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n","\n","            if args.max_steps > 0 and global_step > args.max_steps:\n","                epoch_iterator.close()\n","                break\n","        if args.max_steps > 0 and global_step > args.max_steps:\n","            train_iterator.close()\n","            break\n","\n","    if args.local_rank in [-1, 0]:\n","        tb_writer.close()\n","\n","    return global_step, tr_loss / global_step\n","\n","# Evaluation of some model\n","\n","def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_output_dir = args.output_dir\n","\n","    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n","    os.makedirs(eval_output_dir, exist_ok=True)\n","    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n","    # Note that DistributedSampler samples randomly\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(\n","        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    # multi-gpu evaluate\n","    if args.n_gpu > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    model.eval()\n","\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        inputs, labels = (batch, batch)\n","        inputs = inputs.to(args.device)\n","        labels = labels.to(args.device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs, labels=labels)\n","            lm_loss = outputs[0]\n","            eval_loss += lm_loss.mean().item()\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    perplexity = torch.exp(torch.tensor(eval_loss))\n","\n","    result = {\"perplexity\": perplexity}\n","\n","    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n","    with open(output_eval_file, \"w\") as writer:\n","        logger.info(\"***** Eval results {} *****\".format(prefix))\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCnGAJWbXD9C"},"outputs":[],"source":["# Main runner\n","\n","def main(df_trn, df_val):\n","    args = Args()\n","    \n","    if args.should_continue:\n","        sorted_checkpoints = _sorted_checkpoints(args)\n","        if len(sorted_checkpoints) == 0:\n","            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n","        else:\n","            args.model_name_or_path = sorted_checkpoints[-1]\n","\n","    if (\n","        os.path.exists(args.output_dir)\n","        and os.listdir(args.output_dir)\n","        and args.do_train\n","        and not args.overwrite_output_dir\n","        and not args.should_continue\n","    ):\n","        raise ValueError(\n","            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n","                args.output_dir\n","            )\n","        )\n","\n","    # Setup CUDA, GPU & distributed training\n","    device = torch.device(\"cuda\")\n","    args.n_gpu = torch.cuda.device_count()\n","    args.device = device\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n","    )\n","    logger.warning(\n","        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n","        args.local_rank,\n","        device,\n","        args.n_gpu,\n","        bool(args.local_rank != -1),\n","        args.fp16,\n","    )\n","\n","    # Set seed\n","    set_seed(args)\n","\n","    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n","    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n","    model = AutoModelWithLMHead.from_pretrained(\n","        args.model_name_or_path,\n","        from_tf=False,\n","        config=config,\n","        cache_dir=args.cache_dir,\n","    )\n","    model.to(args.device)\n","    \n","    logger.info(\"Training/evaluation parameters %s\", args)\n","\n","    # Training\n","    if args.do_train:\n","        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n","\n","        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n","        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n","\n","    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n","    if args.do_train:\n","        # Create output directory if needed\n","        os.makedirs(args.output_dir, exist_ok=True)\n","\n","        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n","        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","        # They can then be reloaded using `from_pretrained()`\n","        model_to_save = (\n","            model.module if hasattr(model, \"module\") else model\n","        )  # Take care of distributed/parallel training\n","        model_to_save.save_pretrained(args.output_dir)\n","        tokenizer.save_pretrained(args.output_dir)\n","\n","        # Good practice: save your training arguments together with the trained model\n","        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n","\n","        # Load a trained model and vocabulary that you have fine-tuned\n","        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n","        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n","        model.to(args.device)\n","\n","    # Evaluation\n","    results = {}\n","    if args.do_eval and args.local_rank in [-1, 0]:\n","        checkpoints = [args.output_dir]\n","        if args.eval_all_checkpoints:\n","            checkpoints = list(\n","                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n","            )\n","            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n","            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n","\n","            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"7NWvkdR-XHeB"},"source":["## Run the Main Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["87d93eeb650e4fc0ae87c821e3da820d","f47865e0458347968581937aa9d8acd2","dde45609424749ea9ed8b20d40413ebe","3d6a51a442b24a13a8ddc6b2329193e0","71b454d5cd144c75add7854b924052e0","a38af98743e040389b974f7e99af8500","d3c54d260a1643289ed2a72ef0aabb08","53f3d128632645eab47334c6f2887dba","b25e3f0d45e74122a55c0b0dda296b97","80db37f5576f49a2b00326c02e27d60a","f2b3a262391c4e4b96ab68a4b6e37fe7"]},"executionInfo":{"elapsed":91212,"status":"ok","timestamp":1672271275634,"user":{"displayName":"Kaelyn Haynie","userId":"01388062276589306886"},"user_tz":300},"id":"e61zo2JtXGNX","outputId":"a4869d05-0e93-4d0a-d985-1d5750b633d6"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87d93eeb650e4fc0ae87c821e3da820d","version_major":2,"version_minor":0},"text/plain":["Evaluating:   0%|          | 0/562 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'perplexity_': tensor(2.0748)}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["main(trn_df, val_df)"]},{"cell_type":"markdown","metadata":{"id":"YRpQ_n2zXQj-"},"source":["## Load the Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGw3qgfaXQHX"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-medium')\n","model = AutoModelWithLMHead.from_pretrained('output-medium')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37989,"status":"ok","timestamp":1672273970079,"user":{"displayName":"Kaelyn Haynie","userId":"01388062276589306886"},"user_tz":300},"id":"lAWsiAvNXbxd","outputId":"e13ae227-fb88-40b1-90bf-2173431efd13"},"outputs":[{"name":"stdout","output_type":"stream","text":[">> User:Who are you and where do you work?\n"]},{"name":"stderr","output_type":"stream","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":["Michael Scott: I am Michael and I work at Michael Scott Paper Company.\n",">> User:Who are you and where do you work\n"]},{"name":"stderr","output_type":"stream","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":["Michael Scott: I am Michael, I am a salesman at Michael Scott Paper Co. And I am also a co-manager of Dunder Mifflin Scranton branch.\n",">> User:Who are you and where do you work?\n"]},{"name":"stderr","output_type":"stream","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":["Michael Scott: Dunder Mifflin, and I am also a former employee of Dunder Miffslin.\n",">> User:Who are you and where do you work?\n"]},{"name":"stderr","output_type":"stream","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":["Michael Scott: In this office, we trust.\n"]}],"source":["# Let's chat for 4 lines\n","for step in range(4):\n","    # encode the new user input, add the eos_token and return a tensor in Pytorch\n","    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n","    # print(new_user_input_ids)\n","\n","    # append the new user input tokens to the chat history\n","    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n","\n","    # generated a response while limiting the total chat history to 1000 tokens, \n","    chat_history_ids = model.generate(\n","        bot_input_ids, max_length=200,\n","        pad_token_id=tokenizer.eos_token_id,  \n","        # prevents repeated phrases\n","        no_repeat_ngram_size=5,\n","        # randomizes output\n","        do_sample=True, \n","        # provides a pool of high-probability word candidates\n","        top_k=100, \n","        # provides a likelihood cutoff for chosen wordbranches\n","        top_p=0.8,\n","        # provides on-the-fly responses\n","        temperature=0.9\n","    )\n","    # https://huggingface.co/docs/api-inference/detailed_parameters#text-generation-task\n","    # pretty print last ouput tokens from bot\n","    print(\"Michael Scott: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"]},{"cell_type":"markdown","metadata":{"id":"ANSQlQezXqwn"},"source":["## Push Model to Hugging Face"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgnHRgHKXwDd"},"outputs":[],"source":["!sudo apt-get install git-lfs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhqMtvfmXei8"},"outputs":[],"source":["!git config --global user.email \"your_email@here\"\n","# Tip: using the same email as your huggingface.co account will link your commits to your profile\n","!git config --global user.name \"your_username\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfUsrKR7YLT1"},"outputs":[],"source":["MY_MODEL_NAME = 'model_name'\n","HUGGINGFACE_API_KEY = \"HF_KEY_HERE\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_65nsiLcYNXI"},"outputs":[],"source":["model.push_to_hub(MY_MODEL_NAME, use_auth_token=HUGGINGFACE_API_KEY)\n","tokenizer.push_to_hub(MY_MODEL_NAME, use_auth_token=HUGGINGFACE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"D_XfXTCrZKmO"},"source":["## All Done!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tIwK7G8ZLrd"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"06bb6abc2dcc4c169416f61ee36d8cef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_386fbd302fbb4c609d1d8ad7633690d2","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c76d7d5ebfa744abbf0d6ed503deb919","value":456318}},"0c5df579ff9e45eb8cc7a5ba9bfb782a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fb3ead434684e11a03ec8561d7829d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13834fe4c44d4e9699a4ec6cef8a3bf1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1415c4ad9cbf444081505bdb1e616329":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"188861195b2944bb923d96d49ef92893":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1910a2d3dbe8486b92036a86a520dff9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa7ac1526e748e49657a00d09b7be84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9267d8c8ab97417c87657c21fbffac8c","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f20154f1f464c42b6d6155b2d75ba7d","value":1042301}},"234d1e2c2aab406c9e82c6f21bcc518e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c1a478f25044ce58205cbea01a56f75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"386fbd302fbb4c609d1d8ad7633690d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"389d237c82074e26a08a23591abc8d60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8c412b1329f4114b224acf346c64e0b","placeholder":"​","style":"IPY_MODEL_234d1e2c2aab406c9e82c6f21bcc518e","value":" 456k/456k [00:00&lt;00:00, 12.6MB/s]"}},"3cf9cc28a46a484dad37666d8bd999e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1910a2d3dbe8486b92036a86a520dff9","max":642,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86bcecbbe3674795868e2b96e0d06cdf","value":642}},"3d6a51a442b24a13a8ddc6b2329193e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80db37f5576f49a2b00326c02e27d60a","placeholder":"​","style":"IPY_MODEL_f2b3a262391c4e4b96ab68a4b6e37fe7","value":" 562/562 [00:55&lt;00:00, 10.14it/s]"}},"400f1dae2a804290a25b6d201de170e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f5fc5b1d77342cf8eae01d4098ceda1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1415c4ad9cbf444081505bdb1e616329","placeholder":"​","style":"IPY_MODEL_b9b2bbf4702549c5beccc5e4595339ac","value":"Downloading: 100%"}},"53f3d128632645eab47334c6f2887dba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54a9a19e3ac54075aacefd37773b5dfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57e2fa39f626464b9be881a2c216e5ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13834fe4c44d4e9699a4ec6cef8a3bf1","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ede9f0142c724774a01d404f5f357d5b","value":26}},"59388534c15a4137953e6dd57c25e07a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d6d4f2facfd4eeb88be434a1518b5cc","placeholder":"​","style":"IPY_MODEL_da6526b5b0104a4ea191ea979fcab535","value":"Downloading: 100%"}},"5bf590a2c9244052866b574df710d953":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69d4288ed8e042d6a6fe0f84d26962df","placeholder":"​","style":"IPY_MODEL_9627f4b745614fa69f5af654c6341a15","value":"Downloading: 100%"}},"69d4288ed8e042d6a6fe0f84d26962df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69d95883e5e7463ea1e5c4398223d556":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f5fc5b1d77342cf8eae01d4098ceda1","IPY_MODEL_1fa7ac1526e748e49657a00d09b7be84","IPY_MODEL_ed2c171253a241cd99059585d360886a"],"layout":"IPY_MODEL_0fb3ead434684e11a03ec8561d7829d9"}},"6b669292096d43f7a7f49c48961123fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d6d4f2facfd4eeb88be434a1518b5cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71b454d5cd144c75add7854b924052e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80db37f5576f49a2b00326c02e27d60a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"812e5a3792c541e5b8e3e1eca87fd6e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"853149eb994c4635a7179fed0653da25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86bcecbbe3674795868e2b96e0d06cdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87d93eeb650e4fc0ae87c821e3da820d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f47865e0458347968581937aa9d8acd2","IPY_MODEL_dde45609424749ea9ed8b20d40413ebe","IPY_MODEL_3d6a51a442b24a13a8ddc6b2329193e0"],"layout":"IPY_MODEL_71b454d5cd144c75add7854b924052e0"}},"9267d8c8ab97417c87657c21fbffac8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9627f4b745614fa69f5af654c6341a15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f20154f1f464c42b6d6155b2d75ba7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a38af98743e040389b974f7e99af8500":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8c412b1329f4114b224acf346c64e0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b25e3f0d45e74122a55c0b0dda296b97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9b2bbf4702549c5beccc5e4595339ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb3051de7d234ec085ca9de6b92233c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_812e5a3792c541e5b8e3e1eca87fd6e7","placeholder":"​","style":"IPY_MODEL_2c1a478f25044ce58205cbea01a56f75","value":" 26.0/26.0 [00:00&lt;00:00, 1.24kB/s]"}},"c1a1aac141264f23953eff258fe973a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c676803768654d97905d69639a26dde9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_188861195b2944bb923d96d49ef92893","placeholder":"​","style":"IPY_MODEL_6b669292096d43f7a7f49c48961123fc","value":" 642/642 [00:00&lt;00:00, 32.8kB/s]"}},"c76d7d5ebfa744abbf0d6ed503deb919":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c96dd189c1a241ee87dacfcea226d899":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cde87ff273a1498e950cd4b3a61f76cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bf590a2c9244052866b574df710d953","IPY_MODEL_57e2fa39f626464b9be881a2c216e5ec","IPY_MODEL_bb3051de7d234ec085ca9de6b92233c0"],"layout":"IPY_MODEL_d282dc72caad44c6afe68e5aa74ecff9"}},"d282dc72caad44c6afe68e5aa74ecff9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3c54d260a1643289ed2a72ef0aabb08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da6526b5b0104a4ea191ea979fcab535":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dde45609424749ea9ed8b20d40413ebe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53f3d128632645eab47334c6f2887dba","max":562,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b25e3f0d45e74122a55c0b0dda296b97","value":562}},"e0b619a72e58439eb0e85126df06fca5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c96dd189c1a241ee87dacfcea226d899","placeholder":"​","style":"IPY_MODEL_0c5df579ff9e45eb8cc7a5ba9bfb782a","value":"Downloading: 100%"}},"e60c02ffbb9b4d7cb883cb8aacd0db1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59388534c15a4137953e6dd57c25e07a","IPY_MODEL_06bb6abc2dcc4c169416f61ee36d8cef","IPY_MODEL_389d237c82074e26a08a23591abc8d60"],"layout":"IPY_MODEL_853149eb994c4635a7179fed0653da25"}},"ed2c171253a241cd99059585d360886a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_400f1dae2a804290a25b6d201de170e3","placeholder":"​","style":"IPY_MODEL_54a9a19e3ac54075aacefd37773b5dfa","value":" 1.04M/1.04M [00:00&lt;00:00, 21.2MB/s]"}},"ede9f0142c724774a01d404f5f357d5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f266e1f7c0154223b904d8e2852fd516":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0b619a72e58439eb0e85126df06fca5","IPY_MODEL_3cf9cc28a46a484dad37666d8bd999e1","IPY_MODEL_c676803768654d97905d69639a26dde9"],"layout":"IPY_MODEL_c1a1aac141264f23953eff258fe973a4"}},"f2b3a262391c4e4b96ab68a4b6e37fe7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f47865e0458347968581937aa9d8acd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a38af98743e040389b974f7e99af8500","placeholder":"​","style":"IPY_MODEL_d3c54d260a1643289ed2a72ef0aabb08","value":"Evaluating: 100%"}}}}},"nbformat":4,"nbformat_minor":0}
